# stn_adversarial_examples
Spatial Transformer Network For Adversarial ExamplesGeneration:

The recent extensive use of deep neural networks (DNNs) has brought up the vulnerability o fDNNs to attacks. Adversarial Examples are inputs to the network that were designed to mislead the network and cause false results. A small change in the input can cause the network to errwith high confidence. In classification, the adversarial examples are designed to cause wrongclassification. In this work, we suggest to use a Spatial Transformer Network (STN), a learnablemodule, which explicitly allows the spatial manipulation of data, to create adversarial examples.
